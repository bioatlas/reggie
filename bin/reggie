#!/usr/bin/env python3

import os
import sys
import json
import argparse
import requests

headers = {
    "Accept": "application/json",
    "Content-Type": "application/json"
}

class Reggie:
    def __init__(self, username, password, test):
        self.auth = ( username, password)
        self.api = "https://api.gbif.org/v1"
        if test:
            self.api = "https://api.gbif-uat.org/v1"

    def create(self, title, type, organization, installation, **kwargs):
        data = {
            'title': title,
            'type': type,
            'publishingOrganizationKey': organization,
            'installationKey': installation
        }
        response = requests.post("%s/dataset" % self.api, data=json.dumps(data),
                headers=headers, auth=self.auth)
        print(response)
        print(response.text)
    
    def wipe(self, uuid, **kwargs):
        response = requests.get("%s/dataset/%s/endpoint" % (self.api, uuid))
        for end in response.json():
            key = str(end['key'])
            print("wiping", key)
            requests.delete("%s/dataset/%s/endpoint/%s" % (self.api, uuid, key),
                    auth=self.auth)

    def crawl(self, uuid, **kwargs):
        response = requests.post("%s/dataset/%s/crawl" % (self.api, uuid),
                auth=self.auth)
        if str(response.status_code) == "204":
            print("crawling", uuid)
        else:
            print("unable to crawl dataset (%s)" % response.status_code)

    def endpoint(self, uuid, url, description, **kwargs):
        data = {
            "type": "DWC_ARCHIVE",
            "url": url,
            "description": description
        }
        headers = {"Content-Type": "application/json"}
        response = requests.post("%s/dataset/%s/endpoint" % (self.api, uuid),
                data=json.dumps(data), headers=headers, auth=self.auth)
        show(uuid)

    def show(self, uuid, **kwargs):
        response = requests.get("%s/dataset/%s/endpoint" % (self.api, uuid))
        for end in response.json():
            print("%s / %s" % (end['key'],end['url']))

parser = argparse.ArgumentParser(description='Talk to the GBIF registry')
parser.add_argument("-t", "--test", help="use uat server", action="store_true")
parser.add_argument("-u", "--username", default=os.environ.get("GBIF_USERNAME"))
parser.add_argument("-p", "--password", default=os.environ.get("GBIF_PASSWORD"))

commands = parser.add_subparsers(help='commands')

create = commands.add_parser('create', help='create a new dataset')
create.set_defaults(func="create")
create.add_argument("type", choices=['CHECKLIST', 'METADATA', 'SAMPLING_EVENT', 'OCCURRENCE'])
create.add_argument("title", help='dataset title')
create.add_argument("organization", help='organization uuid')
create.add_argument("installation", help='installation uuid')

show = commands.add_parser('show', help='show information about a dataset')
show.set_defaults(func="show")
show.add_argument("uuid", help='uuid of the dataset')

crawl = commands.add_parser('crawl', help='request a crawl')
crawl.set_defaults(func="crawl")
crawl.add_argument("uuid", help='uuid of the dataset')

wipe = commands.add_parser('wipe', help='wipe all endpoints')
wipe.set_defaults(func="wipe")
wipe.add_argument("uuid", help='uuid of the dataset')

endpoint = commands.add_parser('endpoint', help='set up a new endpoint')
endpoint.set_defaults(func="endpoint")
endpoint.add_argument("uuid", help="uuid of the dataset")
endpoint.add_argument("url", help="endpoint url")
endpoint.add_argument("description", help="endpoint description")

args = parser.parse_args()

reggie = Reggie(args.username, args.password, args.test)

if "func" in args:
    getattr(reggie, args.func)(**vars(args))
else:
    parser.print_help()

